# Dynamic Programming Notes

## Overview of Dynamic Programming (DP)
Dynamic Programming (DP) is a problem-solving technique aimed at solving complex problems by breaking them down into simpler sub-problems. It is particularly useful for optimization problems and can provide solutions in polynomial time.

### Key Characteristics of DP
- **General**: Applicable to various types of problems.
- **Efficient**: Often finds solutions faster than naive approaches.
- **Easy to Understand**: Conceptually clear as it involves breaking problems down.

### Basic Principles
1. **Sub-problems**: Break the problem into smaller, manageable parts.
2. **Overlapping Sub-problems**: Many sub-problems are solved multiple times.
3. **Optimal Substructure**: The optimal solution to the problem can be constructed from optimal solutions of its sub-problems.

## Fibonacci Numbers
### Definition
Fibonacci numbers are defined recursively:
- \( F_1 = 1 \)
- \( F_2 = 1 \)
- \( F_n = F_{n-1} + F_{n-2} \) for \( n > 2 \)

### Recursive Fibonacci Implementation
```python
def fib(n):
    if n <= 2:
        return 1
    else:
        return fib(n - 1) + fib(n - 2)
```
#### Analysis
- This naive recursive approach has exponential time complexity \( O(2^n) \) due to repeated calculations of the same Fibonacci numbers.

### Dynamic Programming Approach
#### Memoization
This involves storing previously computed values to avoid redundant calculations.
```python
memo = {}

def fibDP(n):
    if n in memo:
        return memo[n]
    if n <= 2:
        return 1
    memo[n] = fibDP(n - 1) + fibDP(n - 2)
    return memo[n]
```
#### Time Complexity
- Time: \( O(n) \)
- Space: \( O(n) \) for the memoization dictionary.

### Bottom-Up Approach
This approach computes Fibonacci numbers iteratively:
```python
def fibBottomUp(n):
    if n <= 2:
        return 1
    fib = [0] * (n + 1)
    fib[1], fib[2] = 1, 1
    for i in range(3, n + 1):
        fib[i] = fib[i - 1] + fib[i - 2]
    return fib[n]
```
#### Space Optimization
Since only the last two Fibonacci numbers are needed, space can be reduced to \( O(1) \):
```python
def fibOptimized(n):
    if n <= 2:
        return 1
    prev1, prev2 = 1, 1
    for _ in range(3, n + 1):
        current = prev1 + prev2
        prev2 = prev1
        prev1 = current
    return current
```

## Coin-row Problem
### Problem Statement
Given a row of coins with values, the goal is to maximize the amount collected without picking two adjacent coins.

### Dynamic Programming Approach
Let \( F(n) \) represent the maximum amount collectible from the first \( n \) coins.
- Recurrence Relation:
  - \( F(n) = \max(C[n] + F(n-2), F(n-1)) \)
- Base Cases:
  - \( F(0) = 0 \)
  - \( F(1) = C[1] \)

#### Implementation
```python
def coinRow(C):
    n = len(C)
    F = [0] * (n + 1)
    F[1] = C[0]
    
    for i in range(2, n + 1):
        F[i] = max(C[i - 1] + F[i - 2], F[i - 1])
    
    return F[n]
```
### Time and Space Complexity
- Time: \( O(n) \)
- Space: \( O(n) \) (can be optimized to \( O(1) \) by storing only the last two results).

## Change-making Problem
### Problem Statement
Given denominations of coins, find the minimum number of coins needed to make a certain amount \( n \).

### Dynamic Programming Approach
Let \( F(n) \) be the minimum number of coins needed to make amount \( n \):
- Recurrence Relation:
  - \( F(n) = \min(F(n - d_j) + 1) \) for all denominations \( d_j \) where \( d_j \leq n \)
- Base Case:
  - \( F(0) = 0 \)

#### Implementation
```python
def changeMaking(D, n):
    F = [float('inf')] * (n + 1)
    F[0] = 0
    
    for i in range(1, n + 1):
        for coin in D:
            if coin <= i:
                F[i] = min(F[i], F[i - coin] + 1)
    
    return F[n]
```
### Time and Space Complexity
- Time: \( O(n \cdot m) \) where \( m \) is the number of denominations.
- Space: \( O(n) \).

## General Steps in Dynamic Programming
1. **Characterize the Structure**: Identify the optimal solution structure.
2. **Recursively Define**: Define the value of the optimal solution in terms of smaller sub-problems.
3. **Compute the Value**: Use a bottom-up approach to compute values.
4. **Construct the Solution**: Backtrack to find the optimal solution.

## Conclusion
Dynamic Programming is a powerful technique for solving problems with overlapping sub-problems and optimal substructure. By utilizing memoization or bottom-up approaches, it significantly reduces time complexity compared to naive recursive methods.